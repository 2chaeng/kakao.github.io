---
layout: post
title: '분산 웹 캐시 (Wcache)의 개선과정 - Part 1'
author: sirius.nam
date: 2017-10-16 13:00
tags: [web-cache, storage]
image: /files/covers/kage-idc.jpg
---

# Overview
웹 서비스의 규모가 커지고 이용자의 수가 늘어날 수록 서비스 제공자는 scalability 이슈에 직면하게 됩니다. 
그중 실제 '로딩 속도'의 차이를 느끼게 해주고 트래픽의 대부분을 차지하는 정적 컨텐츠의 신속한 제공은 서비스 품질을 좌우하는 중요한 요소가 되곤 합니다.

![하나의 웹페이지에서도 수많은 컨텐츠가 불려진다](/files/static-contents.png)

이런 수많은 컨텐츠들 (Javascript, css, image)을 빠르게 제공하기 위해 클라이언트와 서버 사이에 위치하여 임시로 저장을 하는 Middlebox를 Web cache라고 합니다.
Web cache 기능은 Apache Traffic Server, Nginx, Squid와 같은 어플리케이션에서 지원하고 있으며, 대량의 컨텐츠를 처리하기 위해 전용 하드웨어 형태의 상용 솔루션도 있습니다.

본 포스트에서는 카카오에서 자체적으로 개발하여 운영중인 Web cache, Wcache에 대한 간략한 소개를 진행하고, 
이어 올해 상반기에 진행되었던 대대적인 구조 개편내역을 다음 포스트에 설명하려 합니다.

# Part 1: 분산 웹 캐시, Wcache

## 개발 배경 및 기본적인 기능
기존에 웹 캐시로 사용되던 상용 솔루션의 문제점은 아래와 같았습니다.
 
 - 장비 대수가 증가함에 따라 늘어나는 라이센스 비용.
 - 버그 수정 및 지원의 어려움.
 - 기능 개선이 불가능하거나 / 느리다.

이런 문제점은 점점 늘어나는 서비스들을 위한 기능 추가 및 장애대응, 트래픽 확장시 걸림돌이 되어 자체적인 솔루션을 개발하게 된 계기가 되었습니다.
C 언어로 구현된 Wcache는 범용 하드웨어(x86)의 자원을 최대한 활용하면서도 안정적인 성능을 낼 수 있도록 하였으며,
(multi-thread, I/O multiplexing, Direct Memory Access) 
[HTTP 표준](https://tools.ietf.org/html/rfc2616)을 준수하는 캐시 정책 및 
Reverse / Forward HTTP Proxy의 기본적인 기능 (HTTP message control, access log, access control 등)을 지원합니다.

## 저장 구조
웹 캐시의 성능은 보통 저장장치의 I/O 속도에 의해 좌우됩니다.[^1] 특히 일정 수준의 cache hit율을 보장하기 위해서 수십~수백 GB의 캐시 용량이 필요한 경우에는
얼마만큼 디스크에 효율적으로 컨텐츠를 저장하고 읽어오는가에 따라 성능이 크게 차이날 수 있습니다.

먼저 컨텐츠 데이터가 저장되는 디스크에는 미리 일정한 크기 (디스크 크기에 따라 64MB ~ 10GB)의 BigFile들을 여러개 생성해 두어 컨텐츠를 저장할 공간을 
확보해 둡니다. 이는 디스크가 연속된 영역에 순차적으로 데이터를 쓸 수 있도록 합니다. 
추가로, 디스크 쓰기 작업을 줄이기 위해 BigFile 내부를 'block' 이라는 세부 구조로 나누어 캐시가 되는 컨텐츠를 바로 저장하지 않고 메모리에 
적재후 block 단위로만 디스크에 쓰는 방식을 취하여 성능 향상을 이끌었습니다.

Metadata에는 URL을 기반으로 한 cache key와 컨텐츠가 저장되어 있는 위치 (BigFile 정보 및 offset)등의 정보를 담고 있으며, 이는 컨텐츠가 저장되는
BigFile과는 별개로 SQLite DB에 저장합니다.
 
디스크와 메모리의 효율적인 사용을 위해 Wcache는 HTTP 헤더와 일부 metadata 정보를 메모리상에 구성해둔 LRU hashtable에 캐싱합니다.
메모리에 캐싱되어 있는 컨텐츠에 대해서는 DB접근 없이 바로 응답이 가능하며, 
캐싱되어 있지 않은 컨텐츠에 접근할때는 DB에서 컨텐츠가 저장되어 있는 BigFile 정보를 읽어 컨텐츠에 대한 정보를 읽어오게 됩니다.
 
![Memory hashtable에 캐싱된 경우 컨텐츠를 접근하는 방법.](/files/wcache-structure.png)

## Wcache의 분산 구성
![Stand alone 상태의 Wcache를 병렬로 구성한 단순한 구조, 각 Wcache에 중복된 컨텐츠들이 캐싱되어있다.](/files/wcache-standalone.png)

초기 Wcache는 위 그림처럼 load balancer(LB) 밑에 여러개의 Wcache 노드를 병렬로 구성하였습니다. 트래픽 대응을 위해서는 괜찮은 구조였지만, LB가
사용자 요청을 단순히 round robin 방식으로 분산하고 있어 모든 Wcache에 중복된 컨텐츠들이 캐싱되어 이 구조로는 원하는 cache hit율을 얻기 힘들었습니다.

![단순한 클러스터 구조. LB(Load Balancer)를 통해 분산되서 온 클라이언트 요청을 해당 컨텐츠가 있는 Wcache로 라우팅 해준다.](/files/wcache-cluster.png)

이를 해결하기 위해 Wcache는 분산 구조를 지원하게 됩니다. 위 그림처럼 여러 대의 Wcache 노드로 구성된 클러스터를 구성하여 
consistent hashing 기법을 이용해 컨텐츠를 고르게 분포시키고, 클라이언트 요청이 들어왔을 때 알맞은 노드에 요청을 라우팅 해주도록 설계 되었습니다.
이 방법은 각 Wcache가 고유한 컨텐츠를 저장함으로써 캐시 효율을 증가시킬수는 있었습니다. 그러나 특정 컨텐츠가 인기가 많은 hot item이 되는 경우,
(위 그림에서 하늘색 컨텐츠)
수많은 요청이 하나의 Wcache로 몰리는 현상이 일어나게 되고, 결국 트래픽을 감당할 수 없게 됩니다.

![Dual layer구조. 1차 layer는 아래의 Wcache들을 하나의 cluster로 바라본다. 2차 layer는 기존처럼 stand alone으로 동작.](/files/wcache-dual-layer.png)

위 문제를 해결하기 위해, 저희는 해당 클러스터 구조를 조금 더 발전시키기로 하였습니다. 
위 그림처럼 Wcache를 두 개의 layer로 나눈 후, 1차 layer에 해당하는 Wcache들이 자신만의 분산 클러스터를 2차 layer로 가지도록 구성을 합니다.
이렇게 구성을 하면 1차 layer에서는 트래픽을 받고, cache miss가 발생했을 경우 2차 layer중 적절한 Wcache 노드에
요청을 합니다.
위 구조의 효과를 배가시키기 위해 1차 layer에 I/O속도가 빠른 SSD를 탑재한 장비를, 2차 layer에는 상대적으로 속도는 느리지만 큰 저장공간을 가진 HDD 탑재 장비를 
두어 빠른 응답속도와 높은 cache hit율, 두 마리의 토끼를 전부 잡을 수 있었습니다. 
특히 소수의 유명한 컨텐츠가 매우 많이 요청되고, 나머지 컨텐츠의 사용 빈도가 기하급수적으로 낮아지는 log tail[^2] 분포를 나타내는 서비스에 대해 매우 효과적인 구조입니다.

## 결론
이렇게 구성한 Wcache는 현재 카카오 서비스에서 수십만 TPS 상당의 트래픽을 안정적으로 처리하고 있습니다. 다음 포스트에서는 Wcache에 잠재되어 있는 문제점이 무엇이 있었는지,
또 어떤 방법으로 해결하였는지에 대해 알아보도록 하겠습니다.

[^1]: [Reducing the Disk I/O of Web Proxy Server Caches](https://www.usenix.org/legacy/event/usenix99/full_papers/maltzahn/maltzahn.pdf)
[^2]: [Long tail distribution](https://en.wikipedia.org/wiki/Long_tail)